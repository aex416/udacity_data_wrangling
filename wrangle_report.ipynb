{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeRateDogs Wrangling Efforts\n",
    "\n",
    "### Gathering Data\n",
    "The first thing step in the data wrangling process is to gather all of the required data sets.  This entailed reading a CSV file, using Python's requests library which was also used to download the data where tweepy was supposed to be used.  Once the data was acquired it was time to assess.\n",
    "\n",
    "### Assessing Data\n",
    "The first step of assessment is visual assessment.  During this step, tidiness issues were identified.  Issues such as separating replies and retweets into their own tables, distilling doggo, floofer pupper, and puppo values into a single variable, turning the three columnar observations found in the image classification table into variables.\n",
    "\n",
    "The second step of assessment includes programmatic assessment.  During this step cleanliness issues were detected.  For the archived twitter table, incorrect value types were identified, columns should not contain HTML, poor extraction of the numerator and denominator rating as well as it should be converted to a ratio to account for photos rated with more than one dog, non-names were identified - and None should be converted to np.nan.  For image prediction, select columns for each observation where the confidence interval was the highest.  Finally, for the twitter JSON data set - display_text_range should be a single character count.\n",
    "\n",
    "### Cleaning Data\n",
    "##### Twitter Archive Table\n",
    "Convert dogtionary values into a single column - dogtionary.  Pandas apply method was used to execute a lambda function across doggo, floofer, pupper, and puppo columns to concatenate them into a single dogtionary variable. \n",
    "\n",
    "In fixing data types, timestamps converted to datetime objects, IDs to objects, dogtionary to category.\n",
    "\n",
    "To address the source column storing HTML, I mapped the values as there were only four of them and used pandas replace method.\n",
    "\n",
    "Numerator and denominator columns were resolved by fixing the regex so that the fraction must end in 0.  Then the rating ratio was calculated by dividing the numerator column by the denominator.\n",
    "\n",
    "To improve name extraction, the name regex was rerun where name in [\"a\", \"None\", \"the\", \"an\"], and the first letter must be capital.\n",
    "\n",
    "##### Image Prediction Table \n",
    "The columns for each observational pass were converted into single variable columns containing data for each pass.  This was done using Pandas melt method.\n",
    "\n",
    "All IDs were converted to objects, and dates converted to datetime objects.\n",
    "\n",
    "Selected the pass which the highest in confidence for each ID - though it turns out that it happened to be p_1 for each row.\n",
    "\n",
    "##### Tweet JSON Tidiness\n",
    "Selected only differing columns from archive table ['id', 'created_at', 'display_text_range', 'favorite_count', 'retweet_count'].\n",
    "\n",
    "Id types were set to object and dates were set to datetime objects.\n",
    "\n",
    "display_text_range was converted to character_count using Panda's str method and the second index."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
